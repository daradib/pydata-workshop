{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Data APIs\n",
    "\n",
    "This lecture material was originally developed by Sam Maurer in 2017, and has been updated.\n",
    "\n",
    "This notebook provides a demonstration of data-access APIs that operate over the web. See README.md for setup instructions.\n",
    "\n",
    "In Part 1, we'll load and parse results from an API feed of earthquake data.  \n",
    "In Part 2, we'll add query parameters to the workflow, using the Mapbox Geolocation API as an example.  \n",
    "In Part 3, we'll use an authenticated API to query public Twitter posts. \n",
    "\n",
    "Before jumping in, let's quickly scan the range of APIs that are available:\n",
    "\n",
    "* Socrata Open Data: https://dev.socrata.com/\n",
    "  * San Francisco: https://datasf.org/opendata/\n",
    "  * Berkeley: https://data.cityofberkeley.info/\n",
    "\n",
    "* Transitland GTFS Feeds: https://transit.land/\n",
    "* Ford Bike Share: https://www.fordgobike.com/system-data\n",
    "\n",
    "* US Census Bureau: https://www.census.gov/data/developers/data-sets.html\n",
    "* Bureau of Labor Statistics: https://www.bls.gov/developers/\n",
    "* US Geological Survey: https://www.usgs.gov/products/data-and-tools/apis\n",
    "* US Environmental Protection Agency: https://www.epa.gov/enviro/web-services\n",
    "\n",
    "* Google APIs: https://console.developers.google.com/apis/library?project=cp255-185021\n",
    "* Facebook: https://developers.facebook.com/docs/apis-and-sdks/\n",
    "* Twitter: https://developer.twitter.com/en/docs/api-reference-index.html\n",
    "* Foursquare: https://developer.foursquare.com/\n",
    "* Instagram: https://www.instagram.com/developer/\n",
    "* Yelp: https://www.yelp.com/developers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Reading from an automated data feed\n",
    "\n",
    "### USGS real-time earthquake feeds\n",
    "\n",
    "This is an API for near-real-time data about earthquakes. Data is provided in JSON format over the web. No authentication is needed, and there's no way to customize the output. Instead, the API has a separate endpoint for each permutation of the data that users might want.\n",
    "\n",
    "**API documentation:**  \n",
    "http://earthquake.usgs.gov/earthquakes/feed/v1.0/geojson.php\n",
    "\n",
    "**Sample API endpoint, for magnitude 4.5+ earthquakes in past day:**  \n",
    "http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/4.5_day.geojson  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import json      # library for working with JSON-formatted text strings\n",
    "import requests  # library for accessing content from web URLs\n",
    "\n",
    "import pprint    # library for cleanly printing Python data structures\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# download data on magnitude 2.5+ quakes from the past week\n",
    "\n",
    "endpoint_url = \"http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_week.geojson\"\n",
    "response = requests.get(endpoint_url)\n",
    "results = response.text\n",
    "\n",
    "# what is the data type of the results?\n",
    "\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"type\":\"FeatureCollection\",\"metadata\":{\"generated\":1539195051000,\"url\":\"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_week.geojson\",\"title\":\"USGS Magnitude 2.5+ Earthquakes, Past Week\",\"status\":200,\"api\":\"1.5.8\",\"count\":270},\"features\":[{\"type\":\"Feature\",\"properties\":{\"mag\":2.88,\"place\":\"3km SW of Anderson Springs, CA\",\"time\":1539190685110,\"updated\":1539192723816,\"tz\":-480,\"url\":\"https://earthquake.usgs.gov/earthquakes/eventpage/nc73095881\",\"detail\":\"https://earthquake.usgs.gov/\n"
     ]
    }
   ],
   "source": [
    "# print the first 500 characters to see a sample of the data\n",
    "\n",
    "print(results[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# it looks like the results are a string with JSON-formatted data inside\n",
    "\n",
    "# parse the string into a Python dictionary (loads = \"load string\")\n",
    "data = json.loads(results)\n",
    "\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the dictionary\n",
    "\n",
    "pp.pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsets of the data can be accessed with square brackets, using labels for the \n",
    "# named elements and numerals for the lists\n",
    "\n",
    "# save the list of quakes to a new variable\n",
    "\n",
    "quakes = data['features']\n",
    "\n",
    "# print the most recent quake\n",
    "\n",
    "pp.pprint(quakes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out the title from each earthquake listing\n",
    "\n",
    "for q in quakes:\n",
    "    print(q['properties']['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out magnitudes and depths into a Pandas dataframe, using\n",
    "# a more compact Python syntax for iterating through lists\n",
    "\n",
    "d = {'magnitude': [q['properties']['mag'] for q in quakes],\n",
    "     'depth': [q['geometry']['coordinates'][2] for q in quakes]}\n",
    "\n",
    "df = pd.DataFrame.from_dict(d)\n",
    "\n",
    "# how many earthquakes were loaded into the dataframe?\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first few lines of data\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some descriptive statistics\n",
    "\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the depth vs. magnitude\n",
    "\n",
    "df.plot(x='magnitude', y='depth', kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to disk\n",
    "\n",
    "df.to_csv('usgs_earthquake_data.csv')\n",
    "\n",
    "print('file saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it back later\n",
    "\n",
    "new_df = pd.read_csv('usgs_earthquake_data.csv')\n",
    "\n",
    "print(new_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Querying an API endpoint\n",
    "\n",
    "### Mapbox Geocoding API\n",
    "\n",
    "Services like Google Maps and Mapbox have various APIs that let you access its services through code instead of through GUI apps. This one from Mapbox lets you look up the latitude-longitude coordinates of street addresses.\n",
    "\n",
    "It works similarly to the earthquakes example, but with query parameters added to the URL endpoint!\n",
    "\n",
    "**API documentation:**  \n",
    "https://www.mapbox.com/api-documentation/#geocoding\n",
    "\n",
    "**API endpoint:**  \n",
    "https://api.mapbox.com/geocoding/v5/mapbox.places\n",
    "\n",
    "**API endpoint with query parameters:**  \n",
    "https://api.mapbox.com/geocoding/v5/mapbox.places/Wurster+Hall.json?access_token=pk.eyJ1IjoiY3AyNTVkZW1vIiwiYSI6ImRPcTlnTUEifQ.3C0d0Nk_rcwV-8JF29PU-w\n",
    "\n",
    "You can get your own access key by signing up for a Mapbox account, if you'd like. Here is a link for that (but don't do it now): https://www.mapbox.com/signin/?route-to=%22/account/access-tokens%22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json      # library for working with JSON-formatted text strings\n",
    "import requests  # library for accessing content from web URLs\n",
    "\n",
    "import pprint    # library for cleanly printing Python data structures\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to encode the search query so that it can be passed as a URL, \n",
    "# with spaces and other special characters removed\n",
    "\n",
    "endpoint = 'https://api.mapbox.com/geocoding/v5/mapbox.places/'\n",
    "\n",
    "address = 'Wurster Hall'\n",
    "\n",
    "params = {'limit': 1,\n",
    "          'access_token': 'pk.eyJ1IjoiY3AyNTVkZW1vIiwiYSI6ImRPcTlnTUEifQ.3C0d0Nk_rcwV-8JF29PU-w'}\n",
    "\n",
    "url = requests.Request('GET', endpoint+address+'.json', params=params).prepare().url\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and parse the results\n",
    "\n",
    "response = requests.get(url)\n",
    "results = response.text\n",
    "data = json.loads(results)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print it more nicely\n",
    "\n",
    "pp.pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out the lat-lon coordinates\n",
    "\n",
    "for r in data['features']:\n",
    "    coords = r['geometry']['coordinates']\n",
    "    print(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "1. Search for some other addresses or landmarks!\n",
    "2. Take a look at the [API documentation](https://www.mapbox.com/api-documentation/#geocoding). Can you figure out how to retrieve other points of interest near Wurster Hall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Querying an API with back-and-forth authentication\n",
    "\n",
    "### Twitter search APIs\n",
    "\n",
    "Twitter's APIs operate over the web as well, but they require a back-and-forth authentication process at the beginning of each connection. It's easier to have a Python library handle this than to create the query URLs ourselves.\n",
    "\n",
    "The Twitter \"REST\" APIs perform stand-alone operations: you submit a query and receive results, like in earlier examples. ([REST](https://en.wikipedia.org/wiki/Representational_state_transfer) is a particular set of guidelines that many APIs follow.) Twitter also has a \"streaming\" API that continues sending results in real time until you disconnect.\n",
    "\n",
    "**API documentation:**  \n",
    "https://dev.twitter.com/rest/public  \n",
    "https://dev.twitter.com/overview/api/tweets\n",
    "\n",
    "**Documentation for the Python helper library**:  \n",
    "http://geduldig.github.io/TwitterAPI/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install TwitterAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from TwitterAPI import TwitterAPI\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import API credentials from keys.py file in the\n",
    "# same directory as this notebook\n",
    "\n",
    "from keys import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up an API connection using credentials from the keys file\n",
    "\n",
    "api = TwitterAPI(consumer_key, consumer_secret, \n",
    "                 access_token, access_token_secret)\n",
    "\n",
    "print(\"Connection is set up but not tested\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a simple data request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most recent tweet from CED\n",
    "\n",
    "endpoint = 'statuses/user_timeline'\n",
    "params = {\n",
    "    'screen_name': 'wursterlife', \n",
    "    'count': 1\n",
    "}\n",
    "r = api.request(endpoint, params)\n",
    "\n",
    "for tweet in r.get_iterator():\n",
    "    print(tweet['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what other data is there?\n",
    "\n",
    "pp.pprint(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other API endpoints allow different types of searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for recent tweets with your favorite emoji\n",
    "\n",
    "endpoint = 'search/tweets'\n",
    "params = {\n",
    "    'q': '👻🎃', \n",
    "    'count': 5\n",
    "}\n",
    "r = api.request(endpoint, params)\n",
    "\n",
    "for tweet in r.get_iterator():\n",
    "    print(tweet['text'] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for public tweets in Korean\n",
    "\n",
    "endpoint = 'search/tweets'\n",
    "params = {\n",
    "    'q': '*', \n",
    "    'lang': 'ko', \n",
    "    'count': 5\n",
    "} \n",
    "r = api.request(endpoint, params)\n",
    "\n",
    "for tweet in r.get_iterator():\n",
    "    print(tweet['text'] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for public tweets geotagged near the UC Berkeley campus\n",
    "\n",
    "endpoint = 'search/tweets'\n",
    "params = {\n",
    "    'q': '*', \n",
    "    'geocode': '37.873,-122.260,0.5km', \n",
    "    'count': 5\n",
    "} \n",
    "r = api.request(endpoint, params)\n",
    "\n",
    "for tweet in r.get_iterator():\n",
    "    print(tweet['text'] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "1. Try some different search queries!\n",
    "2. Display some more data fields in addition to the tweet text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Streaming live tweets in real time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check in: http://bitly.com/cp255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter allows only one or two simultaneous streaming connections for \n",
    "# each set of API credentials, so this part may not work during class\n",
    "\n",
    "endpoint = 'statuses/filter'\n",
    "params = {'locations': '-180,-90,180,90'}\n",
    "r = api.request(endpoint, params)\n",
    "LIMIT = 20\n",
    "\n",
    "# 'enumerate' lets us count tweets as we receive them\n",
    "\n",
    "for i, tweet in enumerate(r.get_iterator()):\n",
    "    print(tweet['created_at'])\n",
    "    print(tweet['place']['full_name'] + ', ' + tweet['place']['country'])\n",
    "    print(tweet['text'] + '\\n')\n",
    "    if (i > LIMIT): break\n",
    "\n",
    "# close the streaming connection\n",
    "r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises for the remainder of class\n",
    "\n",
    "Choose your favorite:\n",
    "\n",
    "1. Make a scatter plot of the lat-lon coordinates of earthquakes.  \n",
    "   &nbsp;\n",
    "   \n",
    "2. The earthquakes API is actually returning a specific data format called [GeoJSON](https://en.wikipedia.org/wiki/GeoJSON), also used by many other geospatial data feeds. Try saving the raw GeoJSON file and opening it in QGIS or in the [geojson.io](http://geojson.io) web viewer.  \n",
    "   &nbsp;\n",
    "\n",
    "2. Using the geocoding example as a starting point, try searching Mapbox's Directions API or Isochrone (travel time contours) API instead. You can read more about them on the [Mapbox API documentation page](https://www.mapbox.com/api-documentation/#introduction).  \n",
    "    &nbsp;\n",
    "\n",
    "3. Try out another API that you're interested in. Can you figure out how to connect to it using Python?  \n",
    "\n",
    "   With municipal data it's often easiest to just download a data file, but APIs are great for querying big data sets or tracking live updates. Here are some resources.\n",
    "\n",
    "   - San Francisco:  https://data.sfgov.org/developers  \n",
    "   - Alameda County:  https://data.acgov.org/developers  \n",
    "   - UC Berkeley:  https://api-central.berkeley.edu  \n",
    "   - US Census:  http://www.census.gov/data/developers/data-sets.html  \n",
    "   - Open Data Network:  https://www.opendatanetwork.com  \n",
    "   - CivicData:  http://www.civicdata.io/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
